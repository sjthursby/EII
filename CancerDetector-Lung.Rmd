---
title: "Untitled"
output: html_document
date: "2025-05-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(readxl)
library(dplyr)
library(reshape2)
library(GenomicRanges)


```

```{r}

#load in LUAD data from TCGA
load("/scratch4/heaswar1/Sara/FromDesktop/EII/TCGA/GDC_TCGA_LUAD/RData/GDC_TCGA_LUAD_betaFUNNORM.Rda")

#aim: overlap with the makers from cancerdetector

#markers:

read_excel("/scratch4/heaswar1/Sara/FromDesktop/EII/EIIAndCancerDetector/S.Table_1.xlsx") -> markers

#need to get the methylation data within the markers
#currently betaFUNNORM only has cgids, need manifest file.
#can get annotations for 450k arrays here:
load("/scratch4/heaswar1/Sara/FromDesktop/EII/EII_ProjectGit/forSara/get450kProbeAnnotations.Rda")

anno <- as.data.frame(anno)

#need column 1, 2, and 4

anno[,c(1,2,4)] -> annoCut

#need an end column for the cgids 
annoCut$end <- annoCut$pos+1

#need to reorganise the columns
annoCut[,c(1,2,4,3)] -> annoCut

colnames(annoCut) <- c("chr", "start", "end", "cgid")


#overlapping the annocut file with the betaFunnorm

betaFUNNORM$cgid <- rownames(betaFUNNORM)

inner_join(annoCut, betaFUNNORM, by="cgid")[,c(1:4)] -> cgidsWithIntervals # only need to know where the cgids reside, I don't need the entire betaFUNNORM object

#need to overlap with markers
  gr2 <- with(markers, GRanges(chr, IRanges(start = start, end = end)))
  
  gr3 <- with(cgidsWithIntervals, GRanges(chr, IRanges(start = start, end = end)))
  
  hits = findOverlaps(gr2, gr3)
  
  z <- cbind(markers[queryHits(hits),], cgidsWithIntervals[subjectHits(hits),])
  
  #rm(gr2, gr3, hits)
  
  #only need columns 1, 2, 3, 4 and 8
  
  z[,c(1,2,3,4,8)] -> matchedMarkers
  
  #rm(z)

#now since we have step 2 markers, we just need to subset matchedMarkers to those in step2markers
  
matchedMarkers[matchedMarkers$marker_index %in% step2markers$marker_index,] -> matchedMarkers

#rm(z)

rm(anno, markers, CpGI_ProbesGenesTable, esBivCpGI_ProbesGenesTable, nonCpGI_ProbesGenesTable, AllIllumina_CpGI.probes, autosomalProbes, CpGI_TSS_Probes, esBivCpGIPromProbes, nonCpGI_TSS_Probes, OpenSea.probes, sexProbes, shelf.probes, shore.probes)

```

```{r}
#Hari wants to make the shapes out of TCGA Lung instead of WGBS Lung, he says there is not enough WGBS Lung----

#subset betaFUNNORM by the accepted markers and then melt.

betaFUNNORM[betaFUNNORM$cgid %in% matchedMarkers$cgid,] -> betaFN



#melt
melt(betaFN, id.vars=c("cgid")) -> betaFNM

#value = beta between 0 and 1

#split into N and T

targets[targets$sampleTypeCode=="NT",1] -> normalSamples

targets[targets$sampleTypeCode=="TP", 1] -> tumorSamples


betaFNM %>%
  mutate(sampleType = case_when(variable %in% normalSamples ~ "Normal",
                                variable %in% tumorSamples ~ "Tumor")) -> betaFNM

na.omit(betaFNM) -> betaFNM #there are NA values in the sampleType column, I suspect they are tumor recurrences

#markersAvailMelt needs a marker_index column

inner_join(betaFNM, matchedMarkers[,c(1,5)], by=c("cgid")) -> betaFNM

#this resulting object appears to be markersAvailMelt in the other scripts.

save(betaFNM, file="/data/heaswar1/Sara/CancerDetector/markersAvailMeltTCGA.RData")

```

```{r}

library(MASS)

# More robust function for beta distribution fitting
fit_beta_distribution <- function(data, max_attempts = 5) {
    # Function to adjust data away from 0 and 1
    adjust_data <- function(x, eps = 1e-6) {
        x[x <= 0] <- eps
        x[x >= 1] <- 1 - eps
        return(x)
    }
    
    # Adjust input data
    data_adj <- adjust_data(data)
    
    # Try different starting values
    for(attempt in 1:max_attempts) {
        tryCatch({
            # Calculate starting values based on current attempt
            x_bar <- mean(data_adj)
            var_x <- var(data_adj)
            
            # Add increasing noise to prevent convergence issues
            noise <- 0.1 * attempt
            shape1 <- max(1, x_bar * ((x_bar * (1 - x_bar)/var_x) - 1) + noise)
            shape2 <- max(1, (1 - x_bar) * ((x_bar * (1 - x_bar)/var_x) - 1) + noise)
            
            # Try fitting with current starting values
            fit <- fitdistr(data_adj, "beta", 
                          start = list(shape1 = shape1, shape2 = shape2),
                          method = "BFGS")
            
            return(fit)
        }, error = function(e) {
            if(attempt == max_attempts) {
                # If all attempts fail, return default values
                return(list(estimate = c(shape1 = 1, shape2 = 1),
                          method = "failed to converge"))
            }
        })
    }
}


```

```{r}

betaFNM[,c(2:5)] -> betaFNM #getting rid of cgid column, not required

distinct(betaFNM) -> betaFNM #checking its removal did not result in repeating rows

betaFNM %>%
      group_by(sampleType, marker_index) %>%
       group_modify(~{
      #starts <- calculate_beta_starts(valueAdj)
    
      #fit <- fitdistr(.$valueAdj, "beta", 
       #           start = list(shape1 = starts$shape1, 
        #                        shape2 = starts$shape2), 
         #                        method="BFGS") #adding a different optimization method
     
      
           fit <- fit_beta_distribution(.$value)
      
      
          data.frame(
          eta = fit$estimate["shape1"],
          rho = fit$estimate["shape2"]
   )
}) -> betaShapesPerMarker

#saved as
save(betaShapesPerMarker, file="/data/heaswar1/Sara/CancerDetector/betaShapesPerMarkerTCGA.RData")




```

```{r}

#removing all the data bar, betaShapesPerMarker, markers, step2markers

#need to read in per read data

#read in the per read measures-------

files <- list.files(path="/scratch4/heaswar1/Austin/EII/results/cfDNA_all_runs", pattern="*.perReadMethylation_RLM.txt", full.names=TRUE)

allfiles <- setNames(lapply(files, read.table, sep="\t", header=F), gsub("_1_bismark_bt2_pe.deduplicated.bam.perReadMethylation_RLM.txt", "", basename(files)))


```

```{r}


lapply(allfiles, function(u){
  u$n_CpGs_unmeth <- u$V6 - u$V7
  
  colnames(u) <- c("chr", "start", "end", "read_name", "CpG_pattern", "n_CpGs", "n_CpGs_methyl", "discordance_score", "transitions_score", "mean_methylation", "n_CpGs_unmeth")
  
  #u$end <- u$start + 1 
  
  u[,c(1:6)] -> u
  
  return(u)
  
}) -> allfiles



#get only regions that overlap with markers
lapply(allfiles, function(y){
  
  gr2 <- with(y, GRanges(chr, IRanges(start = start, end = end)))
  
  gr3 <- with(markers, GRanges(chr, IRanges(start = start, end = end)))
  
  hits = findOverlaps(gr2, gr3)
  
  z <- cbind(y[queryHits(hits),], markers[subjectHits(hits),])
  
  colnames(z) <- c("chr", "start", "end", "read_name", "CpG_pattern", "n_CpGs", "marker_index", "markerChr", "markerStart", "markerEnd")
  
  z[,c(4:7)] -> z
  
  return(z)
  
}) -> allfilesMarkers


melt(allfilesMarkers, id.vars=c("read_name", "CpG_pattern", "n_CpGs", "marker_index")) -> afMarkMelt
#L1 is the sample name

afMarkMelt %>%
  uncount(weights = n_CpGs, .id = "n", .remove = F) %>%
  mutate(readMeth = ifelse(substr(CpG_pattern, n, n) == "G", 1, 0)) -> methPerRead #getting a vector of methylation values (0, 1) per CpG, per read

#going to try and join methPerRead with betaShapesPerMarker by marker_index to try and get eta and rho per marker(with its normal and cancerous shapes)

#methPerRead[,c(1,4,5,6,7)] -> methPerRead

#rm(afMarkMelt, allfiles, allfilesMarkers, markers, files)

#need to split into smaller datsets?

library(purrr)

methPerRead %>%
  group_by(L1) %>%
   group_split() -> mpr

as.list(mpr) -> mpr2 #don't want a vctrs_list_of



#rewriting the below as it is too large for dplyr this way.

#inner_join(methPerRead, betaShapesPerMarker, by="marker_index") -> methShapesJoined #too many rows resulting

#distinct(methShapesJoined) -> methShapesJoined #just in case there are repeated rows from the joins/overlaps 

#saving as methShapesJoinedNoLiver.RData

#save(methShapesJoined, file="methShapesJoinedNoLiver.RData")



lapply(mpr2, function(x){
  
  x <- as.data.frame(x)
  
  return(x)
  
}) -> mpr2 #need to change from tbl to data.frame

lapply(mpr2, function(g){
  
  inner_join(g, betaShapesPerMarker, by="marker_index") -> g
  
  
  return(g)
  
}) -> methShapesJoined

save(methShapesJoined, file="methShapesJoinedTCGA.RData")


```

```{r}

# Then calculate likelihood for each read using the Beta-Bernoulli model
# This will give probabilities like the 0.0009 example


library(gsl) # For beta functions

calculate_methylation_likelihood <- function(r_values, eta, rho) {
    # Calculate numerator: product of B(r_j + eta, 1-r_j + rho)
    numerator <- 1

    
    for(r_j in r_values) {
        if(r_j == 1) {
            numerator <- numerator * beta(1 + eta, rho)
        } else {
            numerator <- numerator * beta(eta, 1 + rho)
        }
    }
    
    # Calculate denominator: B(eta, rho)^3
    denominator <- beta(eta, rho)^length(r_values)
    
    # Calculate final probability
    probability <- numerator/denominator
    
    #return(probability)
    
    return(probability)
    
     
}

# Example usage:
#eta_N <- 2.5  # Your calculated eta parameter for Normal class
#rho_N <- 1.8  # Your calculated rho parameter for Normal class
#r_values <- c(1, 0, 0)  # Example methylation status for 3 CpG sites

#prob_N <- calculate_methylation_likelihood(r_values, eta_N, rho_N)



```

```{r}
load("/data/heaswar1/Sara/CancerDetector/methShapesJoinedTCGA.RData")

#list needs to be made smaller

methShapesJoined1 <- methShapesJoined[1:100]


#part1 of the data
lapply(methShapesJoined1, function(g){
  
  g %>%
    filter(sampleType=="Normal") -> N
  
  g %>%
    filter(sampleType=="Tumor") -> T
  
  inner_join(N, T, by="read_name") -> ntJoin
  
  distinct(ntJoin) -> ntJoin
  
  ntJoin[,c(1,13,15,16,9,10,18,19)] -> ntJoin
  
  colnames(ntJoin) <- c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T")
  
  ntJoin %>%
  group_by(read_name, marker_index) %>%
  mutate(probN = calculate_methylation_likelihood(readMeth, unique(eta_N)[1], unique(rho_N)[1]), probT = calculate_methylation_likelihood(readMeth, unique(eta_T)[1], unique(rho_T)[1])) -> ntJoin
  
  return(ntJoin)
  
}) -> probs1

save(probs1, file="probs1.RData")

#melt into one file
map(probs1, distinct) -> probs1b

read.table("/scratch4/heaswar1/Austin/EII/cfDNA_all_metadata.txt", sep=" ", header=TRUE) -> sampleSheet

setNames(probs1b, sampleSheet[1:100,1]) -> probs1c

melt(probs1c, id.vars=c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T", "probN", "probT")) -> probs1d

probs1d[,c(-3)] -> probs1e

distinct(probs1e) -> probs1e

probs1e[complete.cases(probs1e),] -> probs1e

write.table(probs1e, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs1Distinct.csv", sep=",", col.names = TRUE, row.names = FALSE)

save(probs1e, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs1eDistinct.RData")




```
```{r}
#rm(methShapesJoined, methShapesJoined1, probs1, probs1c, probs1d, probs1e)


#want a deduplicated version that I can save to csv also
#load("/data/heaswar1/Sara/CancerDetector/probs1.RData")

read.table("/scratch4/heaswar1/Austin/EII/cfDNA_all_metadata.txt", sep=" ", header=TRUE) -> sampleSheet #getting sampleNames

setNames(probs1, sampleSheet[1:100,1]) -> probs1b

#melt(probs1b, id.vars=c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T", "probN", "probT")) -> probs1c #melting doesn't work...

#maybe we can write like a 100 csv files so that we can combine them in bash or something else

sampleSheet[1:100, 1] -> sampleNames

lapply(probs1b, function(u){
  
  u[complete.cases(u),] -> u
  
  return(u)
  
}) -> probs1c

rm(probs1b)


for (i in 1:length(probs1c)) {
  
  filename <- paste("/data/heaswar1/Sara/CancerDetector/newProbesTCGA/", "TCGAprobs1", "_sample_", names(probs1c)[i], ".csv", sep="")
  
  print(filename)
  
  write.csv(probs1c[i], file=filename, col.names = TRUE, row.names = FALSE, sep=",")
}




```

```{r}

#changing this to cope with all samples. - ran out of memory, switching to 250


load("/data/heaswar1/Sara/CancerDetector/methShapesJoinedTCGA.RData")

methShapesJoined1 <- methShapesJoined[1:200]


lapply(methShapesJoined1, function(g){
  
  g %>%
    filter(sampleType=="Normal") -> N
  
  g %>%
    filter(sampleType=="Tumor") -> T
  
  inner_join(N, T, by="read_name") -> ntJoin
  
  distinct(ntJoin) -> ntJoin
  
  ntJoin[,c(1,13,15,16,9,10,18,19)] -> ntJoin
  
  colnames(ntJoin) <- c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T")
  
  ntJoin %>%
  group_by(read_name, marker_index) %>%
  mutate(probN = calculate_methylation_likelihood(readMeth, unique(eta_N)[1], unique(rho_N)[1]), probT = calculate_methylation_likelihood(readMeth, unique(eta_T)[1], unique(rho_T)[1])) -> ntJoin
  
  return(ntJoin)
  
}) -> probs1

save(probs1, file="probs1.RData")



#load("/data/heaswar1/Sara/CancerDetector/probs1.RData")

read.table("/scratch4/heaswar1/Austin/EII/cfDNA_all_metadata.txt", sep=" ", header=TRUE) -> sampleSheet #getting sampleNames

setNames(probs1, sampleSheet[1:100,1]) -> probs1

#melt(probs1b, id.vars=c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T", "probN", "probT")) -> probs1c #melting doesn't work...



sampleSheet[1:100, 1] -> sampleNames

lapply(probs1, function(u){
  
  u[complete.cases(u),] -> u
  
  return(u)
  
}) -> probs1


```

```{r}
#test-----
#df_list <- list(probs1c$SRR15143245, probs1c$SRR15143247, probs1c$SRR15143248)

#setNames(df_list, c("SRR15143245", "SRR15143247", "SRR15143248")) -> df_list


df_list <- probs1

```


```{r eval=FALSE, include=FALSE}

library(reticulate)
library(tibble)
library(purrr)

# Import numpy
np <- import("numpy")

# Initialize results list
results <- list()

for (sample_id in names(df_list)) {
  df <- df_list[[sample_id]]

  # Check for required columns
  if (!all(c("probT", "probN") %in% colnames(df))) {
    message("Skipping ", sample_id, ": missing columns")
    next
  }

  # Drop rows with NA
  df <- df[complete.cases(df[, c("probT", "probN")]), ]
  if (nrow(df) == 0) next

  # Create theta values
  theta_values <- seq(0, 0.999, by = 0.001)

  # Compute theta matrix manually in R
  theta_matrix <- outer(df$probT, theta_values, function(pt, t) pt * t + df$probN * (1 - t))

  # Find index of max theta per row
  theta_max_indices <- apply(theta_matrix, 1, which.max)

  # Map index back to theta value
  theta_max_values <- theta_values[theta_max_indices]

  # Calculate average
  avg_max_theta <- mean(theta_max_values)

  # Store result
  results[[sample_id]] <- tibble(L1 = sample_id, max_theta = avg_max_theta)
}

# Combine all results
final_result <- bind_rows(results)
print(final_result)



```
```{r alt_step3_onlyR}
library(dplyr)
library(tibble)
library(purrr)

# Predefine theta values
theta_values <- seq(0, 0.999, by = 0.001)

# Initialize results list
results <- list()

# Define chunk size to simulate pandas chunksize
chunk_size <- 100000

# Loop over each sample in df_list
for (sample_id in names(df_list)) {
  message("Processing sample: ", sample_id)

  df_raw <- df_list[[sample_id]]

  # Safely coerce to tibble and ungroup
  df <- tryCatch({
    df_raw %>%
      as_tibble() %>%
      ungroup() %>%
      select(probT, probN) %>%
      mutate(
        probT = as.numeric(probT),
        probN = as.numeric(probN)
      ) %>%
      filter(!is.na(probT), !is.na(probN))
  }, error = function(e) {
    message("  Skipped: error during cleaning - ", e$message)
    return(NULL)
  })

  # Skip if df is NULL or empty
  if (is.null(df) || nrow(df) == 0) {
    message("  Skipped: no valid rows.")
    next
  }

  max_theta_sum <- 0
  max_theta_count <- 0
  n <- nrow(df)

  # Process in chunks
  for (i in seq(1, n, by = chunk_size)) {
    chunk <- df[i:min(i + chunk_size - 1, n), ]

    # Compute theta matrix using outer product
    theta_matrix <- outer(chunk$probT, theta_values, "*") +
                    outer(chunk$probN, 1 - theta_values, "*")

    # For each row, get the index of the max theta value
    max_theta_indices <- apply(theta_matrix, 1, which.max)
    max_theta_values <- theta_values[max_theta_indices]

    # Update running sum and count
    max_theta_sum <- max_theta_sum + sum(max_theta_values)
    max_theta_count <- max_theta_count + length(max_theta_values)
  }

  # Store result if any valid rows were processed
  if (max_theta_count > 0) {
    avg_max_theta <- max_theta_sum / max_theta_count
    results[[sample_id]] <- tibble(L1 = sample_id, max_theta = avg_max_theta)
    message("  Done: avg_max_theta = ", round(avg_max_theta, 3))
  } else {
    message("  Skipped: no valid max_theta values.")
  }
}

# Combine all valid results into a single data frame
final_result <- bind_rows(results)

save(final_result, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/final_resultTCGA.RData")

# Print or export final result
print(final_result)
```


```{r}

#probs2 samples 101:200


load("/data/heaswar1/Sara/CancerDetector/methShapesJoinedTCGA.RData")

methShapesJoined2 <- methShapesJoined[101:200]


lapply(methShapesJoined2, function(g){
  
  g %>%
    filter(sampleType=="Normal") -> N
  
  g %>%
    filter(sampleType=="Tumor") -> T
  
  inner_join(N, T, by="read_name", relationship="many-to-many") -> ntJoin
  
  distinct(ntJoin) -> ntJoin
  
  ntJoin[,c(1,13,15,16,9,10,18,19)] -> ntJoin
  
  colnames(ntJoin) <- c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T")
  
  ntJoin %>%
  group_by(read_name, marker_index) %>%
  mutate(probN = calculate_methylation_likelihood(readMeth, unique(eta_N)[1], unique(rho_N)[1]), probT = calculate_methylation_likelihood(readMeth, unique(eta_T)[1], unique(rho_T)[1])) -> ntJoin
  
  return(ntJoin)
  
}) -> probs2

save(probs2, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs2.RData")



#load("/data/heaswar1/Sara/CancerDetector/probs1.RData")

read.table("/scratch4/heaswar1/Austin/EII/cfDNA_all_metadata.txt", sep=" ", header=TRUE) -> sampleSheet #getting sampleNames

setNames(probs2, sampleSheet[101:200,1]) -> probs2

#melt(probs1b, id.vars=c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T", "probN", "probT")) -> probs1c #melting doesn't work...


sampleSheet[101:200, 1] -> sampleNames

lapply(probs2, function(u){
  
  u[complete.cases(u),] -> u
  
  return(u)
  
}) -> probs2


save(probs2, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs2.RData")

df_list <- probs2


```

```{r}

#probs3 samples 201:300

library(readxl)
library(dplyr)
library(reshape2)
library(GenomicRanges)

load("/data/heaswar1/Sara/CancerDetector/methShapesJoinedTCGA.RData")

methShapesJoined3 <- methShapesJoined[201:300]


lapply(methShapesJoined3, function(g){
  
  g %>%
    filter(sampleType=="Normal") -> N
  
  g %>%
    filter(sampleType=="Tumor") -> T
  
  inner_join(N, T, by="read_name", relationship="many-to-many") -> ntJoin
  
  distinct(ntJoin) -> ntJoin
  
  ntJoin[,c(1,13,15,16,9,10,18,19)] -> ntJoin
  
  colnames(ntJoin) <- c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T")
  
  ntJoin %>%
  group_by(read_name, marker_index) %>%
  mutate(probN = calculate_methylation_likelihood(readMeth, unique(eta_N)[1], unique(rho_N)[1]), probT = calculate_methylation_likelihood(readMeth, unique(eta_T)[1], unique(rho_T)[1])) -> ntJoin
  
  return(ntJoin)
  
}) -> probs3

save(probs3, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs3.RData")



#load("/data/heaswar1/Sara/CancerDetector/probs1.RData")

read.table("/scratch4/heaswar1/Austin/EII/cfDNA_all_metadata.txt", sep=" ", header=TRUE) -> sampleSheet #getting sampleNames

setNames(probs3, sampleSheet[201:300,1]) -> probs3

#melt(probs1b, id.vars=c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T", "probN", "probT")) -> probs1c #melting doesn't work...


sampleSheet[201:300, 1] -> sampleNames

lapply(probs3, function(u){
  
  u[complete.cases(u),] -> u
  
  return(u)
  
}) -> probs3


save(probs3, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs3.RData")

df_list <- probs3


```

```{r alt_step3_onlyR}
library(dplyr)
library(tibble)
library(purrr)

load("/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs2.RData")

df_list <- probs2

# Predefine theta values
theta_values <- seq(0, 0.999, by = 0.001)

# Initialize results list
results <- list()

# Define chunk size to simulate pandas chunksize
chunk_size <- 100000

# Loop over each sample in df_list
for (sample_id in names(df_list)) {
  message("Processing sample: ", sample_id)

  df_raw <- df_list[[sample_id]]

  # Safely coerce to tibble and ungroup
  df <- tryCatch({
    df_raw %>%
      as_tibble() %>%
      ungroup() %>%
      select(probT, probN) %>%
      mutate(
        probT = as.numeric(probT),
        probN = as.numeric(probN)
      ) %>%
      filter(!is.na(probT), !is.na(probN))
  }, error = function(e) {
    message("  Skipped: error during cleaning - ", e$message)
    return(NULL)
  })

  # Skip if df is NULL or empty
  if (is.null(df) || nrow(df) == 0) {
    message("  Skipped: no valid rows.")
    next
  }

  max_theta_sum <- 0
  max_theta_count <- 0
  n <- nrow(df)

  # Process in chunks
  for (i in seq(1, n, by = chunk_size)) {
    chunk <- df[i:min(i + chunk_size - 1, n), ]

    # Compute theta matrix using outer product
    theta_matrix <- outer(chunk$probT, theta_values, "*") +
                    outer(chunk$probN, 1 - theta_values, "*")

    # For each row, get the index of the max theta value
    max_theta_indices <- apply(theta_matrix, 1, which.max)
    max_theta_values <- theta_values[max_theta_indices]

    # Update running sum and count
    max_theta_sum <- max_theta_sum + sum(max_theta_values)
    max_theta_count <- max_theta_count + length(max_theta_values)
  }

  # Store result if any valid rows were processed
  if (max_theta_count > 0) {
    avg_max_theta <- max_theta_sum / max_theta_count
    results[[sample_id]] <- tibble(L1 = sample_id, max_theta = avg_max_theta)
    message("  Done: avg_max_theta = ", round(avg_max_theta, 3))
  } else {
    message("  Skipped: no valid max_theta values.")
  }
}

# Combine all valid results into a single data frame
final_result <- bind_rows(results)

save(final_result, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/final_resultTCGA2.RData")

# Print or export final result
print(final_result)
```

```{r}

#probs4 samples 301:400

library(readxl)
library(dplyr)
library(reshape2)
library(GenomicRanges)

load("/data/heaswar1/Sara/CancerDetector/methShapesJoinedTCGA.RData")

methShapesJoined4 <- methShapesJoined[301:400]


lapply(methShapesJoined4, function(g){
  
  g %>%
    filter(sampleType=="Normal") -> N
  
  g %>%
    filter(sampleType=="Tumor") -> T
  
  inner_join(N, T, by="read_name", relationship="many-to-many") -> ntJoin
  
  distinct(ntJoin) -> ntJoin
  
  ntJoin[,c(1,13,15,16,9,10,18,19)] -> ntJoin
  
  colnames(ntJoin) <- c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T")
  
  ntJoin %>%
  group_by(read_name, marker_index) %>%
  mutate(probN = calculate_methylation_likelihood(readMeth, unique(eta_N)[1], unique(rho_N)[1]), probT = calculate_methylation_likelihood(readMeth, unique(eta_T)[1], unique(rho_T)[1])) -> ntJoin
  
  return(ntJoin)
  
}) -> probs4

save(probs4, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs4.RData")



#load("/data/heaswar1/Sara/CancerDetector/probs1.RData")

read.table("/scratch4/heaswar1/Austin/EII/cfDNA_all_metadata.txt", sep=" ", header=TRUE) -> sampleSheet #getting sampleNames

setNames(probs4, sampleSheet[301:400,1]) -> probs4

#melt(probs1b, id.vars=c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T", "probN", "probT")) -> probs1c #melting doesn't work...


sampleSheet[301:400, 1] -> sampleNames

lapply(probs4, function(u){
  
  u[complete.cases(u),] -> u
  
  return(u)
  
}) -> probs4


save(probs4, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs4.RData")

df_list <- probs4


```

```{r alt_step3_onlyR}
library(dplyr)
library(tibble)
library(purrr)

#load("/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs2.RData")

df_list <- probs4

# Predefine theta values
theta_values <- seq(0, 0.999, by = 0.001)

# Initialize results list
results <- list()

# Define chunk size to simulate pandas chunksize
chunk_size <- 100000

# Loop over each sample in df_list
for (sample_id in names(df_list)) {
  message("Processing sample: ", sample_id)

  df_raw <- df_list[[sample_id]]

  # Safely coerce to tibble and ungroup
  df <- tryCatch({
    df_raw %>%
      as_tibble() %>%
      ungroup() %>%
      select(probT, probN) %>%
      mutate(
        probT = as.numeric(probT),
        probN = as.numeric(probN)
      ) %>%
      filter(!is.na(probT), !is.na(probN))
  }, error = function(e) {
    message("  Skipped: error during cleaning - ", e$message)
    return(NULL)
  })

  # Skip if df is NULL or empty
  if (is.null(df) || nrow(df) == 0) {
    message("  Skipped: no valid rows.")
    next
  }

  max_theta_sum <- 0
  max_theta_count <- 0
  n <- nrow(df)

  # Process in chunks
  for (i in seq(1, n, by = chunk_size)) {
    chunk <- df[i:min(i + chunk_size - 1, n), ]

    # Compute theta matrix using outer product
    theta_matrix <- outer(chunk$probT, theta_values, "*") +
                    outer(chunk$probN, 1 - theta_values, "*")

    # For each row, get the index of the max theta value
    max_theta_indices <- apply(theta_matrix, 1, which.max)
    max_theta_values <- theta_values[max_theta_indices]

    # Update running sum and count
    max_theta_sum <- max_theta_sum + sum(max_theta_values)
    max_theta_count <- max_theta_count + length(max_theta_values)
  }

  # Store result if any valid rows were processed
  if (max_theta_count > 0) {
    avg_max_theta <- max_theta_sum / max_theta_count
    results[[sample_id]] <- tibble(L1 = sample_id, max_theta = avg_max_theta)
    message("  Done: avg_max_theta = ", round(avg_max_theta, 3))
  } else {
    message("  Skipped: no valid max_theta values.")
  }
}

# Combine all valid results into a single data frame
final_result <- bind_rows(results)

save(final_result, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/final_resultTCGA4.RData")

# Print or export final result
print(final_result)
```

```{r}

#probs5 samples 401:475

library(readxl)
library(dplyr)
library(reshape2)
library(GenomicRanges)

load("/data/heaswar1/Sara/CancerDetector/methShapesJoinedTCGA.RData")

methShapesJoined4 <- methShapesJoined[401:475]


lapply(methShapesJoined4, function(g){
  
  g %>%
    filter(sampleType=="Normal") -> N
  
  g %>%
    filter(sampleType=="Tumor") -> T
  
  inner_join(N, T, by="read_name", relationship="many-to-many") -> ntJoin
  
  distinct(ntJoin) -> ntJoin
  
  ntJoin[,c(1,13,15,16,9,10,18,19)] -> ntJoin
  
  colnames(ntJoin) <- c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T")
  
  ntJoin %>%
  group_by(read_name, marker_index) %>%
  mutate(probN = calculate_methylation_likelihood(readMeth, unique(eta_N)[1], unique(rho_N)[1]), probT = calculate_methylation_likelihood(readMeth, unique(eta_T)[1], unique(rho_T)[1])) -> ntJoin
  
  return(ntJoin)
  
}) -> probs5

save(probs5, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs5.RData")



#load("/data/heaswar1/Sara/CancerDetector/probs1.RData")

read.table("/scratch4/heaswar1/Austin/EII/cfDNA_all_metadata.txt", sep=" ", header=TRUE) -> sampleSheet #getting sampleNames

setNames(probs5, sampleSheet[401:475,1]) -> probs5

#melt(probs1b, id.vars=c("read_name", "marker_index", "n", "readMeth", "eta_N", "rho_N", "eta_T", "rho_T", "probN", "probT")) -> probs1c #melting doesn't work...


sampleSheet[401:475, 1] -> sampleNames

lapply(probs5, function(u){
  
  u[complete.cases(u),] -> u
  
  return(u)
  
}) -> probs5


save(probs5, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs5.RData")

df_list <- probs5


```

```{r alt_step3_onlyR}
library(dplyr)
library(tibble)
library(purrr)

load("/data/heaswar1/Sara/CancerDetector/newProbesTCGA/probs5.RData")

df_list <- probs5

# Predefine theta values
theta_values <- seq(0, 0.999, by = 0.001)

# Initialize results list
results <- list()

# Define chunk size to simulate pandas chunksize
chunk_size <- 100000

# Loop over each sample in df_list
for (sample_id in names(df_list)) {
  message("Processing sample: ", sample_id)

  df_raw <- df_list[[sample_id]]

  # Safely coerce to tibble and ungroup
  df <- tryCatch({
    df_raw %>%
      as_tibble() %>%
      ungroup() %>%
      select(probT, probN) %>%
      mutate(
        probT = as.numeric(probT),
        probN = as.numeric(probN)
      ) %>%
      filter(!is.na(probT), !is.na(probN))
  }, error = function(e) {
    message("  Skipped: error during cleaning - ", e$message)
    return(NULL)
  })

  # Skip if df is NULL or empty
  if (is.null(df) || nrow(df) == 0) {
    message("  Skipped: no valid rows.")
    next
  }

  max_theta_sum <- 0
  max_theta_count <- 0
  n <- nrow(df)

  # Process in chunks
  for (i in seq(1, n, by = chunk_size)) {
    chunk <- df[i:min(i + chunk_size - 1, n), ]

    # Compute theta matrix using outer product
    theta_matrix <- outer(chunk$probT, theta_values, "*") +
                    outer(chunk$probN, 1 - theta_values, "*")

    # For each row, get the index of the max theta value
    max_theta_indices <- apply(theta_matrix, 1, which.max)
    max_theta_values <- theta_values[max_theta_indices]

    # Update running sum and count
    max_theta_sum <- max_theta_sum + sum(max_theta_values)
    max_theta_count <- max_theta_count + length(max_theta_values)
  }

  # Store result if any valid rows were processed
  if (max_theta_count > 0) {
    avg_max_theta <- max_theta_sum / max_theta_count
    results[[sample_id]] <- tibble(L1 = sample_id, max_theta = avg_max_theta)
    message("  Done: avg_max_theta = ", round(avg_max_theta, 3))
  } else {
    message("  Skipped: no valid max_theta values.")
  }
}

# Combine all valid results into a single data frame
final_result <- bind_rows(results)

save(final_result, file="/data/heaswar1/Sara/CancerDetector/newProbesTCGA/final_resultTCGA5.RData")

# Print or export final result
print(final_result)
```

```{r}

#make the boxplot------
bind_rows(results) -> results5 #part five all 75 samples

#rm(chunk, df, df_list, df_raw, probs5, theta_matrix, avg_max_theta, chunk_size, i, max_theta_count, max_theta_indices, max_theta_sum, max_theta_values, n, sample_id, theta_values)

#load in the other parts
load("/data/heaswar1/Sara/CancerDetector/newProbesTCGA/final_resultTCGA4.RData")
final_result -> results4 #part4

load("/data/heaswar1/Sara/CancerDetector/newProbesTCGA/final_resultTCGA2.RData")
final_result -> results2 #part2

load("/data/heaswar1/Sara/CancerDetector/newProbesTCGA/final_resultTCGA3.RData")
final_result -> results3 #part3

load("/data/heaswar1/Sara/CancerDetector/newProbesTCGA/final_resultTCGA.RData")
final_result -> results1 #part1

#bind together
rbind(results1, results2, results3, results4, results5) -> resultsAll

#join with sample sheet
inner_join(resultsAll, sampleSheet[,c(1,33,34,35)], by=c("L1"="Run")) -> resultsAll

#make the plot
library(ggplot2)

ggplot(resultsAll, aes(x=ground.truth, y=max_theta, fill=ground.truth)) + geom_boxplot()

ggplot(resultsAll, aes(x=stage, y=max_theta, fill=stage)) + geom_boxplot() + ggtitle("CancerDetector on Lung")


```
```{r}

#make AUC

#example
# Example data (replace with your data)
#scores <- c(3.2, 1.5, 4.0, 2.8, 0.5, 5.0)  # Predictor scores
#labels <- c(0, 0, 1, 1, 0, 1)              # True labels (0/1)

#in this case, 
#scores needs to be created

resultsAll$prediction <- if_else(resultsAll$max_theta > 0.1, 1, 0)

#labels = resultsAll$ground.truth but it needs converted into 0 and 1

resultsAll$GT <- if_else(resultsAll$ground.truth == "normal", 0, 1)

scores <- resultsAll$prediction

labels <- resultsAll$GT

#Sort scores in descending order and reorder labels accordingly:
ordered_indices <- order(-scores)  # Indices for descending order
sorted_scores <- scores[ordered_indices]
sorted_labels <- labels[ordered_indices]

#Step 3: Calculate TPR and FPR
#Iterate through thresholds (each unique score) and compute metrics:
total_pos <- sum(labels)    # Total actual positives
total_neg <- length(labels) - total_pos  # Total actual negatives

# Initialize cumulative counters
tp <- cumsum(sorted_labels == 1)  # Cumulative true positives
fp <- cumsum(sorted_labels == 0)  # Cumulative false positives

# Calculate TPR and FPR at each threshold (including endpoints)
tpr <- c(0, tp / total_pos)       # Starts at (0,0)
fpr <- c(0, fp / total_neg)       # Ends at (1,1)

library(ggplot2)

# Assume 'fpr' and 'tpr' are calculated as in previous steps
specificity <- 1 - fpr

ggplot(data.frame(Specificity = specificity, Sensitivity = tpr), 
       aes(Specificity, Sensitivity)) +
  geom_line(color = "blue") +
  #geom_abline(intercept = 0.95, color = "black") +
  geom_vline(xintercept = 0.95, color = "black") +
  scale_x_reverse() +  # Reverse x-axis to show specificity
  labs(x = "Specificity", y = "Sensitivity", title = "ROC Curve of CancerDetector Predictions in Lung")


```
```{r}

auc_value <- sum(diff(fpr) * (head(tpr, -1) + tail(tpr, -1)) / 2)
print(auc_value)

```

